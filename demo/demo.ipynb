{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "os.chdir(\"/home/bkk4001/repos/LoMaR\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_example_config():  # without density, ver_1 data, visit aug off, no risk, with long early stop, survival.\n",
    "    config = {}\n",
    "    config['exp_id'] = 0\n",
    "    # model\n",
    "    config['n_past_visits'] = 5 # present point + 4 years of history\n",
    "    config['n_future_dx'] = 5 # 5 follow-up years\n",
    "    config['input_embedding_dim'] = 512\n",
    "    config['model_embedding_dim'] = 128\n",
    "    config['n_heads'] = 4\n",
    "    config['global_do_rate'] = 0.1\n",
    "    # config['model_weight_dir'] = \"/midtier/sablab/scratch/bkk4001/miccai_breast/exp_34/model_weights/rt_1_rv_0_ri_0/i_param_7/model_weights.pth\"\n",
    "    config['model_weight_dir'] = \"\"\n",
    "    # data\n",
    "    config['path_to_csv'] = \"demo/data/demo_metadata.csv\"\n",
    "    config['n_pseudo'] = 1 # number of pseudo test sets for evaluation\n",
    "    # results\n",
    "    config['results_dir'] = \"demo/results/\"\n",
    "    return config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import copy\n",
    "\n",
    "class BreastDataset(Dataset):\n",
    "    def __init__(self, config, history_masking_id=None):\n",
    "        # Store config.\n",
    "        self.config = config\n",
    "\n",
    "        # Load the master CSV that contains per-patient info:\n",
    "        # - paths to per-visit embedding .npy files (e.g., npy_-4, ..., npy_0)\n",
    "        # - future diagnosis labels (e.g., dx_1, ..., dx_K)\n",
    "        # - split assignment (trainvaltest column)\n",
    "        past_visits = pd.read_csv(config['path_to_csv'], low_memory=False)\n",
    "\n",
    "        # Determine history length (number of past visits) from config.\n",
    "        # We represent visits with relative year codes:\n",
    "        #   n_past_visits=5  -> [-4, -3, -2, -1,  0]\n",
    "        n_past_visits = int(config['n_past_visits'])\n",
    "        history_years = list(range(-(n_past_visits - 1), 1))\n",
    "\n",
    "        # Optional: synthetic \"history masking\" to ablate certain visit slots.\n",
    "        # If enabled, we will treat some visits as missing even if they exist in the CSV.\n",
    "        # Convention: pattern value 1 => mask (hide) this visit, 0 => keep it if present.\n",
    "        history_masking_id_dict = None\n",
    "        if history_masking_id is not None:\n",
    "            patterns = {\n",
    "                0: [1, 1, 1, 1, 0],\n",
    "                1: [1, 1, 1, 0, 0],\n",
    "                2: [1, 1, 0, 0, 0],\n",
    "                3: [1, 0, 0, 0, 0],\n",
    "                4: [0, 0, 0, 0, 0],\n",
    "                5: [0, 1, 0, 1, 0],\n",
    "                6: [1, 1, 0, 1, 0],\n",
    "            }\n",
    "            # Map each year code (e.g., -4..0) to a {0,1} masking decision.\n",
    "            keys = history_years\n",
    "            history_masking_id_dict = dict(zip(keys, patterns[history_masking_id]))\n",
    "\n",
    "        # Save dataset state.\n",
    "        self.history_masking_id = history_masking_id\n",
    "        self.history_masking_id_dict = history_masking_id_dict\n",
    "\n",
    "        # Keep a copy for indexing and record dataset size.\n",
    "        self.past_visits = past_visits.copy()\n",
    "        self.len_data = len(self.past_visits)\n",
    "\n",
    "        # Map string labels in the CSV to numeric values.\n",
    "        # Note: Unknown is mapped to -1; training code typically needs to ignore/handle these separately.\n",
    "        self.label_dict = {\n",
    "            \"Not Malignant\": 0,\n",
    "            \"Malignant\": 1,\n",
    "            \"Unknown\": -1,\n",
    "        }\n",
    "\n",
    "    def __len__(self):\n",
    "        # Number of patient rows in this split.\n",
    "        return int(self.len_data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sample = {}\n",
    "\n",
    "        # Recompute history year codes from config to keep __getitem__ self-contained.\n",
    "        n_past_visits = int(self.config['n_past_visits'])\n",
    "        history_years = list(range(-(n_past_visits - 1), 1))\n",
    "        viscodes = np.array(history_years)\n",
    "\n",
    "        # Get the CSV row for this patient/sample.\n",
    "        patient_data = self.past_visits.iloc[idx]\n",
    "\n",
    "        # We will build:\n",
    "        # - embeddings: list of per-visit embedding vectors (or zero vectors if missing)\n",
    "        # - visit_mask: indicates \"missing after masking\" (0=present, 1=missing/masked)\n",
    "        # - original_visit_mask: indicates \"truly missing in data\" (0=present, 1=missing)\n",
    "        embeddings = []\n",
    "        visit_mask = []\n",
    "        original_visit_mask = []\n",
    "\n",
    "        if self.history_masking_id_dict is not None:\n",
    "            # Masking enabled: some existing visits are artificially treated as missing.\n",
    "            for history_year in history_years:\n",
    "                has_file = (pd.isna(patient_data['npy_' + str(history_year)]) == False)\n",
    "                is_masked = (self.history_masking_id_dict[history_year] == 1)\n",
    "\n",
    "                if has_file and (not is_masked):\n",
    "                    # Load precomputed embedding from disk.\n",
    "                    visit_embeddings = np.load(patient_data['npy_' + str(history_year)])\n",
    "                    embeddings.append(visit_embeddings)\n",
    "                    visit_mask.append(0)\n",
    "                else:\n",
    "                    # If missing or masked out, use a zero vector placeholder.\n",
    "                    # (512 is assumed embedding dim; should match how embeddings were saved.)\n",
    "                    embeddings.append(np.zeros((512)))\n",
    "                    visit_mask.append(1)\n",
    "\n",
    "                # Track the true missingness (ignoring synthetic masking).\n",
    "                original_visit_mask.append(0 if has_file else 1)\n",
    "        else:\n",
    "            # No masking: missingness is purely determined by whether the file path exists in CSV.\n",
    "            for history_year in history_years:\n",
    "                if pd.isna(patient_data['npy_' + str(history_year)]) == False:\n",
    "                    visit_embeddings = np.load(patient_data['npy_' + str(history_year)])\n",
    "                    embeddings.append(visit_embeddings)\n",
    "                    visit_mask.append(0)\n",
    "                    original_visit_mask.append(0)\n",
    "                else:\n",
    "                    embeddings.append(np.zeros((512)))\n",
    "                    visit_mask.append(1)\n",
    "                    original_visit_mask.append(1)\n",
    "\n",
    "        # Stack into arrays:\n",
    "        # - visit_embeddings: [T, D]\n",
    "        # - visit_mask: [T]\n",
    "        # - original_visit_mask: [T]\n",
    "        embeddings = np.stack(embeddings)\n",
    "        visit_mask = np.array(visit_mask)\n",
    "        original_visit_mask = np.array(original_visit_mask)\n",
    "\n",
    "        # Future survival labels across horizons 1..K where K = config['n_future_dx'].\n",
    "        # The CSV is expected to have columns: dx_1, dx_2, ..., dx_K.\n",
    "        n_future_dx = int(self.config['n_future_dx'])\n",
    "        surv_cols = ['dx_' + str(z) for z in range(1, n_future_dx + 1)]\n",
    "\n",
    "        # Map string labels to numeric; missing values are treated as \"Unknown\" (-1).\n",
    "        label = np.array([float(self.label_dict[z]) for z in patient_data[surv_cols].fillna('Unknown')])\n",
    "\n",
    "        # Package sample dict (NumPy arrays). Often converted to torch tensors in a collate_fn or training loop.\n",
    "        sample['visit_embeddings'] = embeddings\n",
    "        sample['visit_mask'] = visit_mask\n",
    "        sample['original_visit_mask'] = np.array(original_visit_mask)\n",
    "        sample['viscodes'] = viscodes\n",
    "        sample['label'] = label\n",
    "\n",
    "        return sample\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "\n",
    "import time\n",
    "\n",
    "import torch\n",
    "import copy \n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# from lomar.model import *\n",
    "# from demo.dataset import *\n",
    "exec(open(\"/home/bkk4001/repos/LoMaR/lomar/model.py\").read())\n",
    "\n",
    "\n",
    "def compute_metrics(outputs, labels):\n",
    "    \"\"\"\n",
    "    Compute ROC-AUC metrics for a multi-horizon prediction setting.\n",
    "\n",
    "    Args:\n",
    "        outputs: numpy array of shape [B, K] with predicted scores/logits per horizon.\n",
    "        labels:  numpy array of shape [B, K] with binary labels {0,1} or -1 for unknown.\n",
    "\n",
    "    Returns:\n",
    "        List: [avg_rocauc, rocauc_year1, rocauc_year2, ...]\n",
    "              avg_rocauc ignores NaNs (years where ROC-AUC is undefined).\n",
    "    \"\"\"\n",
    "    rocauc_scores = []\n",
    "\n",
    "    for i in range(labels.shape[1]):\n",
    "        # Slice labels/predictions for horizon i (e.g., year i+1).\n",
    "        year_labels = labels[:, i]\n",
    "        year_predictions = outputs[:, i]\n",
    "\n",
    "        # Only evaluate on valid labels (here: -1 means Unknown).\n",
    "        mask = (year_labels != -1)\n",
    "\n",
    "        # ROC-AUC is defined only if both classes {0,1} are present in the filtered labels.\n",
    "        if len(np.unique(year_labels[mask])) == 2:\n",
    "            rocauc_score = roc_auc_score(year_labels[mask], year_predictions[mask])\n",
    "            rocauc_scores.append(rocauc_score)\n",
    "        else:\n",
    "            rocauc_scores.append(float('nan'))\n",
    "\n",
    "    # Average ROC-AUC across horizons, ignoring undefined horizons (NaNs).\n",
    "    avg_rocauc = np.nanmean(rocauc_scores)\n",
    "    \n",
    "    # Return average first, then per-horizon scores.\n",
    "    return [avg_rocauc] + rocauc_scores\n",
    "\n",
    "def evalute(model, test_dataset, test_loader, config):\n",
    "        \"\"\"\n",
    "        Run a single forward pass over the entire test_loader (assumed full-batch),\n",
    "        then compute pseudo-group ROC-AUC metrics based on dataset-provided boolean\n",
    "        columns (pseudo_0, pseudo_1, ...).\n",
    "\n",
    "        Note:\n",
    "            - This function currently takes only the *first batch* from test_loader.\n",
    "              In the demo() setup, batch_size=len(test_dataset), so this corresponds\n",
    "              to evaluating the full dataset in one pass.\n",
    "        \"\"\"\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            # Fetch a single batch (in this demo: the full dataset).\n",
    "            batch = next(iter(test_loader))\n",
    "\n",
    "            # Labels: [B, K] where K = number of future horizons (e.g., 5 years).\n",
    "            labels = batch['label'].to(config['torch_device'])\n",
    "\n",
    "            # Model outputs: expected [B, K].\n",
    "            outputs = model(batch)\n",
    "\n",
    "        # Collect results per pseudo split/group.\n",
    "        pseudo_results = pd.DataFrame()\n",
    "        for i_pseudo in range(config['n_pseudo']):\n",
    "            # Ensure there is a boolean column pseudo_i in the dataset dataframe.\n",
    "            # If absent, default to True for all rows (i.e., use all samples).\n",
    "            \n",
    "            # Note that if you are using a subject multiple times in your meta csv, \n",
    "            # you must set the pseudo indices so that each subject is used only once \n",
    "            # in a pseudo test set. Otherwise your evaluation will be biased. Please \n",
    "            # refer to the paper for more info.\n",
    "            if \"pseudo_\"+str(i_pseudo) in test_dataset.past_visits.columns:\n",
    "                pass \n",
    "            else: \n",
    "                test_dataset.past_visits[\"pseudo_\"+str(i_pseudo)] = True\n",
    "\n",
    "            # Boolean indexing mask over rows/samples.\n",
    "            indices = test_dataset.past_visits[\"pseudo_\"+str(i_pseudo)]\n",
    "\n",
    "            # Filter predictions/labels for this pseudo group and compute ROC-AUCs.\n",
    "            pseudo_preds = outputs[indices].detach().cpu().numpy()\n",
    "            pseudo_labels = labels[indices].detach().cpu().numpy()\n",
    "            pseudo_rocauc = compute_metrics(pseudo_preds, pseudo_labels)\n",
    "\n",
    "            # Store results in a dataframe for easy averaging/printing.\n",
    "            pseudo_results.loc[i_pseudo, 'history_masking_id'] = test_dataset.history_masking_id\n",
    "            cols = ['1_year', '2_year', '3_year', '4_year', '5_year']\n",
    "            pseudo_results.loc[i_pseudo, cols] = pseudo_rocauc[1:6]\n",
    "\n",
    "        # Average across pseudo groups; indexed by history_masking_id for convenience.\n",
    "        average_pseudo_results = pd.DataFrame(columns=pseudo_results.columns)\n",
    "        average_pseudo_results.loc[test_dataset.history_masking_id] = pseudo_results.mean()\n",
    "\n",
    "        # Pack outputs for downstream analysis / saving.\n",
    "        res = {}\n",
    "        res['labels'] = labels.detach().cpu().numpy()\n",
    "        res['outputs'] = outputs.detach().cpu().numpy()\n",
    "        res['average_pseudo_results'] = average_pseudo_results\n",
    "        return res\n",
    "\n",
    "def demo(config):\n",
    "    \"\"\"\n",
    "    Demo inference script:\n",
    "      - Loads a trained LoMaR checkpoint\n",
    "      - Evaluates across multiple history masking settings (0..6)\n",
    "      - Computes pseudo-group ROC-AUC metrics\n",
    "      - Saves all outputs into an .npz log file\n",
    "    \"\"\"\n",
    "\n",
    "    the_log = {}\n",
    "    the_log['config'] = config \n",
    "\n",
    "    # Pick device automatically (GPU if available).\n",
    "    config['torch_device'] = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    \n",
    "    print(\"config:\")\n",
    "    print(config)\n",
    "  \n",
    "    # Create model and load pretrained weights.\n",
    "    model = LoMaR(config)\n",
    "    if config['model_weight_dir']:\n",
    "        model.load_state_dict(torch.load(config['model_weight_dir']), strict=True)\n",
    "    model.eval()\n",
    "    print(\"Loaded the model, moving to inference.\")\n",
    "    \n",
    "    inference_log = {}\n",
    "\n",
    "    # Evaluate multiple synthetic history masking settings (ablation / robustness check).\n",
    "    for history_masking_id in range(7):\n",
    "     \n",
    "        # Dataset is expected to apply the requested history masking internally.\n",
    "        test_dataset =  BreastDataset(config, history_masking_id)\n",
    "\n",
    "        # Full-batch loader: one batch contains all samples.\n",
    "        test_loader = DataLoader(test_dataset, batch_size=len(test_dataset), shuffle=False)\n",
    "\n",
    "        print(\"Starting evaluation for history_masking_id:\", history_masking_id)\n",
    "        start_time = time.time()\n",
    "        test_evaluation_results = evalute(model, test_dataset, test_loader, config)\n",
    "        end_time = time.time()\n",
    "        print(f\"Execution time: {end_time - start_time:.2f} seconds\")\n",
    "        \n",
    "        print(test_evaluation_results['average_pseudo_results'])\n",
    "        \n",
    "        # Store results under the masking id key.\n",
    "        inference_log[test_dataset.history_masking_id] = test_evaluation_results\n",
    "        \n",
    "    # Save the full inference log to disk.\n",
    "    the_log['inference'] = inference_log\n",
    "    log_dir = config['results_dir']\n",
    "    if not os.path.exists(log_dir):\n",
    "        os.makedirs(log_dir)\n",
    "    \n",
    "    np.savez(log_dir+'/log_inference.npz', **the_log)       \n",
    "    print(\"Saved results to:\")\n",
    "    print(log_dir+'exp_'+str(config['exp_id'])+'_log_inference.npz')\n",
    "    print('Done!')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [],
   "source": [
    "# past_visits = pd.read_csv('/midtier/sablab/scratch/bkk4001/karolinska/splits_0305_aicluster/rt_'+str(1)+'_rv_'+str(0)+'/'+'past_visits_0305.csv', low_memory=False)\n",
    "# past_visits = past_visits.loc[past_visits['trainvaltest'] == 'test'].reset_index(drop=True)\n",
    "# past_visits = past_visits.drop_duplicates(subset=['subject'], keep='last').reset_index(drop=True)\n",
    "# past_visits = past_visits.iloc[:100]\n",
    "\n",
    "# meta_cols = ['subject']\n",
    "# dx_cols = [z for z in past_visits.columns if \"dx_\" in z]\n",
    "# imageuid_cols = [\"imageuid_\"+str(z) for z in [-4, -3, -2, -1, 0]]\n",
    "# dx_cols.sort()\n",
    "# # rename: imageuid_*  -> npy_*\n",
    "# rename_map = {c: c.replace(\"imageuid_\", \"npy_\") for c in imageuid_cols}\n",
    "# past_visits = past_visits.rename(columns=rename_map)\n",
    "\n",
    "# # after renaming, update the list of cols to keep\n",
    "# npy_cols = [rename_map[c] for c in imageuid_cols]\n",
    "\n",
    "\n",
    "# for i in range(len(past_visits)):\n",
    "#     npy_cols = [\"npy_\"+str(z) for z in [-4, -3, -2, -1, 0]]\n",
    "#     for npy_col in npy_cols:\n",
    "#         row = past_visits.loc[i, npy_col]\n",
    "#         if pd.isna(row) == False:\n",
    "#             npy = np.load(row)\n",
    "#             # print(row)\n",
    "#             row = 'demo/data/npy_files/' + row.split('/')[-1]\n",
    "#             # print(row)\n",
    "#             np.save(row, npy[:512])\n",
    "#             past_visits.loc[i, npy_col] = row    \n",
    "            \n",
    "# past_visits = past_visits[meta_cols + dx_cols + npy_cols]\n",
    "# past_visits.to_csv(\"/home/bkk4001/repos/LoMaR/demo/data/demo_metadata.csv\", index=False)\n",
    "\n",
    "\n",
    "# past_visits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "config:\n",
      "{'exp_id': 0, 'n_past_visits': 5, 'n_future_dx': 5, 'input_embedding_dim': 512, 'model_embedding_dim': 128, 'n_heads': 4, 'global_do_rate': 0.1, 'model_weight_dir': '', 'path_to_csv': 'demo/data/demo_metadata.csv', 'n_pseudo': 1, 'results_dir': 'demo/results/', 'torch_device': device(type='cuda')}\n",
      "Loaded the model, moving to inference.\n",
      "Starting evaluation for history_masking_id: 0\n",
      "Execution time: 0.08 seconds\n",
      "   history_masking_id   1_year    2_year    3_year    4_year    5_year\n",
      "0                 0.0  0.23435  0.297203  0.356061  0.541667  0.583333\n",
      "Starting evaluation for history_masking_id: 1\n",
      "Execution time: 0.09 seconds\n",
      "   history_masking_id    1_year    2_year    3_year    4_year    5_year\n",
      "1                 1.0  0.210273  0.291958  0.348485  0.520833  0.583333\n",
      "Starting evaluation for history_masking_id: 2\n",
      "Execution time: 0.11 seconds\n",
      "   history_masking_id    1_year    2_year    3_year    4_year    5_year\n",
      "2                 2.0  0.396469  0.382867  0.409091  0.583333  0.666667\n",
      "Starting evaluation for history_masking_id: 3\n",
      "Execution time: 0.12 seconds\n",
      "   history_masking_id    1_year    2_year    3_year    4_year    5_year\n",
      "3                 3.0  0.370787  0.351399  0.409091  0.583333  0.666667\n",
      "Starting evaluation for history_masking_id: 4\n",
      "Execution time: 0.14 seconds\n",
      "   history_masking_id    1_year    2_year    3_year    4_year    5_year\n",
      "4                 4.0  0.386838  0.356643  0.371212  0.541667  0.666667\n",
      "Starting evaluation for history_masking_id: 5\n",
      "Execution time: 0.12 seconds\n",
      "   history_masking_id    1_year    2_year    3_year  4_year    5_year\n",
      "5                 5.0  0.452648  0.424825  0.356061     0.5  0.583333\n",
      "Starting evaluation for history_masking_id: 6\n",
      "Execution time: 0.10 seconds\n",
      "   history_masking_id    1_year    2_year    3_year    4_year    5_year\n",
      "6                 6.0  0.410915  0.396853  0.409091  0.583333  0.666667\n",
      "Saved results to:\n",
      "demo/results/exp_0_log_inference.npz\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "config = get_example_config()\n",
    "demo(config)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (f23)",
   "language": "python",
   "name": "f23"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "36cd75b219d45b3a984485502468ab74c9ad6fe72cd972f8e74f0f21876b8a76"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
